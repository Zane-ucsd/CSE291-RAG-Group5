# 🏋️ Sports Injury RAG Retrieval

This repository contains a **Retrieval-Augmented Generation (RAG)** retrieval pipeline based on **Elasticsearch vector search**.
We use a sports injury knowledge base (5 categories, 6000+ chunks from 119 PDFs) embedded with OpenAI’s `text-embedding-3-small` model (1536 dimensions) and indexed in Elasticsearch for hybrid semantic–keyword retrieval.

---

## 📂 Project Structure

```
.
├── yours_api.txt                       # API for Elasticsearch and openai
├── body.json                           # curl command's body part to generate Elasticsearch API key
├── ES                                  # Jupyter experiments / setup
├── new_vector_db_dump_clean.sql        # Original data dump from PostgreSQL
├── rag_requests_with_category_embeddings.json  # Query set with embeddings
├── retrieval_results_60.xlsx           # Top-60 KNN candidates (16 queries × 60 results)
├── retrieval_results.xlsx              # Final processed retrieval results
└── README.md                           # You are here
```

---

## 🧭 1. Environment Setup

### Dependencies

```bash
pip install elasticsearch openai numpy
```

### Elasticsearch

* Version: `9.2.0`
* Download: [https://www.elastic.co/downloads/elasticsearch](https://www.elastic.co/downloads/elasticsearch)
* Start Elasticsearch:

```bash
.\elasticsearch.bat
```

Default URL:

```
https://localhost:9200
```

If you see SSL warnings, add the CA certificate (`http_ca.crt`) in your client configuration.

---

## 🔐 2. Authentication & API Key

We use Elasticsearch API key authentication.
`body.json` contains the exact curl command's body part
```

You’ll get:

```json
{
  "id": "...",
  "api_key": "...",
  "encoded": "..."
}
```

Python connection example:

```python
from elasticsearch import Elasticsearch
es = Elasticsearch(
    "https://localhost:9200",
    api_key=("API_KEY_ID", "API_KEY"),
    ca_certs="path/to/http_ca.crt"
)
print(es.info())
```

Each query embedding is generated using OpenAI’s text-embedding-3-small API. And the results are saved in rag_requests_with_category_embeddings.json.

---

## 🧠 3. Database Import

### Step 1 — Load into PostgreSQL

```bash
createdb new_vector_db
psql -U postgres -d new_vector_db -f new_vector_db_dump_clean.sql
```

Check:

```bash
psql -U postgres -d new_vector_db -c "SELECT COUNT(*) FROM knowledge_base;"
```

### Step 2 — Export for Elasticsearch

```sql
SELECT id, category, content, embedding, source FROM knowledge_base;
```

* `embedding` is a string like `[0.1, 0.2, ...]`.
* Convert to `float[]` in Python before upload.
* All vectors are pre-normalized with L2 norm.

### Step 3 — Create Elasticsearch Index

```json
PUT /sports_kb
{
  "mappings": {
    "properties": {
      "id": {"type": "keyword"},
      "category": {"type": "keyword"},
      "source": {"type": "keyword"},
      "content": {"type": "text"},
      "embedding": {
        "type": "dense_vector",
        "dims": 1536,
        "index": true,
        "similarity": "cosine"
      }
    }
  }
}
```

---

## 📝 4. Query Format

The RAG evaluation queries are stored in:

```
rag_requests_with_category_embeddings.json
```

Each entry:

```json
{
  "id": 10,
  "text": "An amateur footballer experienced sudden sharp pain in the back of the thigh while sprinting...",
  "category": "Soccer",
  "embedding": [0.003, -0.012, ...]
}
```

* `id`: query ID
* `text`: natural language question
* `category`: one of `{badminton, cycling, running, soccer, swimming}`
* `embedding`: 1536-dim normalized vector (generated by `text-embedding-3-small`)

---

## 🔍 5. Retrieval

The core script is:

```
retrieval/run_retrieval.py
```

Run:

```bash
python retrieval/run_retrieval.py
```

Two retrieval modes are executed:

1. **KNN retrieval** using cosine similarity
2. **Hybrid retrieval** using `KNN + BM25` keyword search

### What it does

* Reads all 16 request embeddings
* Performs KNN (Top 60) + optional category filter
* Performs hybrid retrieval with keyword boost
* Prints all candidate scores and metadata
* Writes aligned IDs to `retrieval_results_60.xlsx`

---

## 📊 6. Output Format

### `retrieval_results_60.xlsx`

* **16 columns**, one per request
* **60 rows**, representing candidate rank
* Each cell contains the retrieved document ID at that rank.

```
Request_1,Request_2,...,Request_16
doc_129,doc_812,...,doc_77
doc_315,doc_231,...,doc_108
...
```

### `retrieval_results.xlsx`

* Optional processed version for downstream evaluation or visualization.

### Console Output Example

```
===== Request #10 | category=soccer =====
TEXT: An amateur footballer experienced...

-- KNN + Filter (Top 60) --
 1/60. score=0.8532 | cat=soccer | src=paper_21.pdf | Hamstring injuries are common...
 2/60. score=0.8497 | cat=soccer | src=paper_12.pdf | Muscle strain can be identified...
 ...
```

---

## 📡 7. API Reference

The file `api.txt` contains:

* Elasticsearch API key creation
* Index creation
* Example search queries:

  * KNN search
  * Hybrid search (KNN + BM25)
* Authentication format

---

## 🧾 8. Useful Tips

* We use cosine similarity through `dense_vector` + KNN interface.
* Hybrid search score = `knn_score + bm25_score`.
* BM25 tends to dominate; use `boost` to adjust weights if needed.
* All embeddings are precomputed (no API call during retrieval).
* Recommended: normalize embeddings before uploading to ES.

---

## 🧪 9. Example Visualization

```
 ┌────────────────────┐
 │   Requests (JSON)   │
 │ text + embedding    │
 └────────┬────────────┘
          │
          ▼
 ┌────────────────────┐
 │  KNN Search (ES)   │───► Top-60 IDs → CSV
          │
          ▼
 ┌────────────────────┐
 │ Hybrid Search (ES) │───► Top-10 Score + Context → CSV
 └────────────────────┘
```

