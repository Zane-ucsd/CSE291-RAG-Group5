{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISS Vector Retrieval System for Sports Injuries Knowledge Base\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to use FAISS to retrieve relevant chunks from the sports injuries knowledge base.\n",
    "\n",
    "**Data Details:**\n",
    "- **File**: `new_vector_db_dump.sql` (120MB)\n",
    "- **Records**: 6000+ chunks from 119 PDFs\n",
    "- **Categories**: 5 sports (badminton, cycling, running, soccer, swimming)\n",
    "- **Embedding Model**: OpenAI text-embedding-3-small\n",
    "- **Embedding Dimensions**: 1536\n",
    "- **Similarity Metric**: Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully!\n",
      "FAISS version: 1.9.0\n",
      "NumPy version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")\n",
    "print(f\"FAISS version: {faiss.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Parse SQL Dump File\n",
    "\n",
    "Extract embeddings and metadata directly from the PostgreSQL dump file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sql_dump(sql_file_path: str) -> Tuple[List[Dict], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Parse PostgreSQL dump file and extract data.\n",
    "    \n",
    "    Returns:\n",
    "        metadata: List of dictionaries with id, category, content, source\n",
    "        embeddings: NumPy array of shape (n, 1536)\n",
    "    \"\"\"\n",
    "    print(f\"Reading SQL dump from: {sql_file_path}\")\n",
    "    \n",
    "    metadata = []\n",
    "    embeddings_list = []\n",
    "    \n",
    "    with open(sql_file_path, 'r', encoding='utf-8') as f:\n",
    "        in_copy_section = False\n",
    "        \n",
    "        for line in f:\n",
    "            # Detect start of data section\n",
    "            if line.startswith('COPY public.knowledge_base'):\n",
    "                in_copy_section = True\n",
    "                print(\"Found data section...\")\n",
    "                continue\n",
    "            \n",
    "            # Detect end of data section\n",
    "            if in_copy_section and line.startswith('\\\\.'):\n",
    "                in_copy_section = False\n",
    "                print(\"Finished parsing data section\")\n",
    "                break\n",
    "            \n",
    "            # Parse data lines\n",
    "            if in_copy_section and line.strip():\n",
    "                try:\n",
    "                    # Split by tabs (PostgreSQL COPY format)\n",
    "                    parts = line.strip().split('\\t')\n",
    "                    \n",
    "                    if len(parts) >= 5:\n",
    "                        record_id = int(parts[0])\n",
    "                        category = parts[1]\n",
    "                        content = parts[2]\n",
    "                        embedding_str = parts[3]\n",
    "                        source = parts[4] if len(parts) > 4 else ''\n",
    "                        \n",
    "                        # Parse embedding: \"[0.123, 0.456, ...]\" -> list of floats\n",
    "                        embedding_str = embedding_str.strip('[]')\n",
    "                        embedding = [float(x) for x in embedding_str.split(',')]\n",
    "                        \n",
    "                        if len(embedding) == 1536:\n",
    "                            metadata.append({\n",
    "                                'id': record_id,\n",
    "                                'category': category,\n",
    "                                'content': content,\n",
    "                                'source': source\n",
    "                            })\n",
    "                            embeddings_list.append(embedding)\n",
    "                        \n",
    "                        if len(metadata) % 1000 == 0:\n",
    "                            print(f\"  Parsed {len(metadata)} records...\")\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    # Skip problematic lines\n",
    "                    continue\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    embeddings = np.array(embeddings_list, dtype='float32')\n",
    "    \n",
    "    print(f\"\\n✓ Successfully parsed {len(metadata)} records\")\n",
    "    print(f\"✓ Embeddings shape: {embeddings.shape}\")\n",
    "    \n",
    "    return metadata, embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading SQL dump from: new_vector_db_dump_clean.sql\n",
      "Found data section...\n",
      "  Parsed 1000 records...\n",
      "  Parsed 2000 records...\n",
      "  Parsed 3000 records...\n",
      "Finished parsing data section\n",
      "\n",
      "✓ Successfully parsed 3117 records\n",
      "✓ Embeddings shape: (3117, 1536)\n"
     ]
    }
   ],
   "source": [
    "# Parse the SQL dump file\n",
    "sql_file = 'new_vector_db_dump_clean.sql'\n",
    "metadata, embeddings = parse_sql_dump(sql_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample metadata:\n",
      "Total records: 3117\n",
      "\n",
      "First record:\n",
      "  ID: 1\n",
      "  Category: badminton\n",
      "  Source: IJHSR08.pdf\n",
      "  Content preview: 1 BPT Intern, Modern College of Physiotherapy, Pune, Maharashtra, India. 2 Associate professor, P.E.S Modern College of Physiotherapy, Pune, Maharashtra, India Corresponding Author: Shantanu Kshirsaga...\n",
      "\n",
      "Embedding shape: (3117, 1536)\n",
      "Embedding sample: [-0.04253524 -0.02639948  0.07209279 -0.00048227  0.00677258]...\n"
     ]
    }
   ],
   "source": [
    "# Display sample data\n",
    "print(\"Sample metadata:\")\n",
    "print(f\"Total records: {len(metadata)}\")\n",
    "print(f\"\\nFirst record:\")\n",
    "print(f\"  ID: {metadata[0]['id']}\")\n",
    "print(f\"  Category: {metadata[0]['category']}\")\n",
    "print(f\"  Source: {metadata[0]['source']}\")\n",
    "print(f\"  Content preview: {metadata[0]['content'][:200]}...\")\n",
    "print(f\"\\nEmbedding shape: {embeddings.shape}\")\n",
    "print(f\"Embedding sample: {embeddings[0][:5]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category distribution:\n",
      "soccer       867\n",
      "cycling      696\n",
      "swimming     685\n",
      "badminton    538\n",
      "running      331\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check category distribution\n",
    "categories = [m['category'] for m in metadata]\n",
    "category_counts = pd.Series(categories).value_counts()\n",
    "print(\"\\nCategory distribution:\")\n",
    "print(category_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.5: Extract Swimming Data for LLM Analysis\n",
    "\n",
    "Extract swimming-related entries and format them for LLM to create test queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Filtered 685 swimming entries\n",
      "✓ Filtered embeddings shape: (685, 1536)\n"
     ]
    }
   ],
   "source": [
    "def filter_by_category(metadata, embeddings, category='swimming'):\n",
    "    \"\"\"\n",
    "    Filter metadata and embeddings by category.\n",
    "    \n",
    "    Args:\n",
    "        metadata: List of metadata dictionaries\n",
    "        embeddings: NumPy array of embeddings\n",
    "        category: Category to filter (default: 'swimming')\n",
    "    \n",
    "    Returns:\n",
    "        Filtered metadata and embeddings\n",
    "    \"\"\"\n",
    "    filtered_metadata = []\n",
    "    filtered_indices = []\n",
    "    \n",
    "    for idx, meta in enumerate(metadata):\n",
    "        if meta['category'] == category:\n",
    "            filtered_metadata.append(meta)\n",
    "            filtered_indices.append(idx)\n",
    "    \n",
    "    filtered_embeddings = embeddings[filtered_indices]\n",
    "    \n",
    "    print(f\"✓ Filtered {len(filtered_metadata)} {category} entries\")\n",
    "    print(f\"✓ Filtered embeddings shape: {filtered_embeddings.shape}\")\n",
    "    \n",
    "    return filtered_metadata, filtered_embeddings\n",
    "\n",
    "# Filter swimming data\n",
    "swimming_metadata, swimming_embeddings = filter_by_category(metadata, embeddings, 'swimming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved formatted data to: /Users/apple/Desktop/swimming_entries_for_llm.txt\n",
      "✓ Generated 643066 characters of formatted text\n",
      "\n",
      "First 500 characters preview:\n",
      "# Swimming Injuries Knowledge Base Entries\n",
      "\n",
      "Total Entries: 685\n",
      "================================================================================\n",
      "\n",
      "ID: 6001\n",
      "<!-- image --> <!-- image --> <!-- image --> At our club we try to get the swimmers 'comfortable being uncomfortable' we train 9 times a week and most of our training is race based training to get the swimmers used to training at high speeds and that definitely makes them uncomfortable most of the time. So its important to get 'comfortable bein\n"
     ]
    }
   ],
   "source": [
    "def format_for_llm(filtered_metadata, max_entries=None, output_file=None):\n",
    "    \"\"\"\n",
    "    Format filtered data in a clean, readable format for LLM analysis.\n",
    "    \n",
    "    Args:\n",
    "        filtered_metadata: List of filtered metadata dictionaries\n",
    "        max_entries: Maximum number of entries to include (None = all)\n",
    "        output_file: Optional file path to save the formatted text\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string\n",
    "    \"\"\"\n",
    "    entries_to_process = filtered_metadata[:max_entries] if max_entries else filtered_metadata\n",
    "    \n",
    "    # Create formatted text (shorter format: only ID and content)\n",
    "    formatted_text = f\"# Swimming Injuries Knowledge Base Entries\\n\\n\"\n",
    "    formatted_text += f\"Total Entries: {len(entries_to_process)}\\n\"\n",
    "    formatted_text += f\"=\" * 80 + \"\\n\\n\"\n",
    "    \n",
    "    for i, entry in enumerate(entries_to_process, 1):\n",
    "        formatted_text += f\"ID: {entry['id']}\\n\"\n",
    "        formatted_text += f\"{entry['content']}\\n\"\n",
    "    \n",
    "    # Save to file if specified\n",
    "    if output_file:\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(formatted_text)\n",
    "        print(f\"✓ Saved formatted data to: {output_file}\")\n",
    "    \n",
    "    return formatted_text\n",
    "\n",
    "# Format swimming data for LLM\n",
    "swimming_text = format_for_llm(\n",
    "    swimming_metadata, \n",
    "    max_entries=685,  # Adjust as needed (None = all entries)\n",
    "    output_file='/Users/apple/Desktop/swimming_entries_for_llm.txt'\n",
    ")\n",
    "\n",
    "print(f\"✓ Generated {len(swimming_text)} characters of formatted text\")\n",
    "print(f\"\\nFirst 500 characters preview:\")\n",
    "print(swimming_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build FAISS Index\n",
    "\n",
    "Create a FAISS index using `IndexFlatIP` (Inner Product) for cosine similarity. **Important**: Normalize vectors before adding to the index!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building FAISS index with dimension: 1536\n",
      "Normalizing embeddings...\n",
      "Adding 3117 vectors to index...\n",
      "✓ FAISS index built successfully!\n",
      "  Total vectors in index: 3117\n"
     ]
    }
   ],
   "source": [
    "def build_faiss_index(embeddings: np.ndarray) -> faiss.IndexFlatIP:\n",
    "    \"\"\"\n",
    "    Build a FAISS index with normalized embeddings for cosine similarity.\n",
    "    \n",
    "    Args:\n",
    "        embeddings: NumPy array of shape (n, 1536)\n",
    "    \n",
    "    Returns:\n",
    "        FAISS index\n",
    "    \"\"\"\n",
    "    dimension = embeddings.shape[1]\n",
    "    print(f\"Building FAISS index with dimension: {dimension}\")\n",
    "    \n",
    "    # Create IndexFlatIP (Inner Product) for cosine similarity\n",
    "    index = faiss.IndexFlatIP(dimension)\n",
    "    \n",
    "    # Normalize embeddings for cosine similarity\n",
    "    print(\"Normalizing embeddings...\")\n",
    "    faiss.normalize_L2(embeddings)\n",
    "    \n",
    "    # Add embeddings to index\n",
    "    print(f\"Adding {len(embeddings)} vectors to index...\")\n",
    "    index.add(embeddings)\n",
    "    \n",
    "    print(f\"✓ FAISS index built successfully!\")\n",
    "    print(f\"  Total vectors in index: {index.ntotal}\")\n",
    "    \n",
    "    return index\n",
    "\n",
    "# Build the index\n",
    "index = build_faiss_index(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Set Up OpenAI API for Query Embeddings\n",
    "\n",
    "You need to use the **same model** (`text-embedding-3-small`) to generate query vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenAI API configured\n",
      "⚠️ Remember to set your OPENAI_API_KEY environment variable!\n"
     ]
    }
   ],
   "source": [
    "# Set up OpenAI API\n",
    "# Replace with your actual API key\n",
    "OPENAI_API_KEY = \"\"\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "# Or if you already have it in environment:\n",
    "client = OpenAI()  # Will use OPENAI_API_KEY from environment\n",
    "\n",
    "def get_query_embedding(query: str, model: str = \"text-embedding-3-small\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate embedding for a query using OpenAI API.\n",
    "    \n",
    "    Args:\n",
    "        query: Query text\n",
    "        model: OpenAI embedding model (must be text-embedding-3-small)\n",
    "    \n",
    "    Returns:\n",
    "        NumPy array of shape (1536,)\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(\n",
    "        input=query,\n",
    "        model=model\n",
    "    )\n",
    "    \n",
    "    embedding = np.array(response.data[0].embedding, dtype='float32')\n",
    "    \n",
    "    # Normalize for cosine similarity\n",
    "    embedding = embedding.reshape(1, -1)\n",
    "    faiss.normalize_L2(embedding)\n",
    "    \n",
    "    return embedding[0]\n",
    "\n",
    "print(\"✓ OpenAI API configured\")\n",
    "print(\"⚠️ Remember to set your OPENAI_API_KEY environment variable!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Perform Similarity Search\n",
    "\n",
    "Search the FAISS index and retrieve the most relevant chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_chunks(\n",
    "    query: str,\n",
    "    index: faiss.IndexFlatIP,\n",
    "    metadata: List[Dict],\n",
    "    top_k: int = 60,\n",
    "    category_filter: str = None\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Search for similar chunks using FAISS.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query text\n",
    "        index: FAISS index\n",
    "        metadata: List of metadata dictionaries\n",
    "        top_k: Number of results to return\n",
    "        category_filter: Optional category filter (e.g., 'running', 'soccer')\n",
    "    \n",
    "    Returns:\n",
    "        List of results with content, score, category, and source\n",
    "    \"\"\"\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Searching for top {top_k} results...\")\n",
    "    \n",
    "    # Get query embedding\n",
    "    query_embedding = get_query_embedding(query)\n",
    "    query_embedding = query_embedding.reshape(1, -1)\n",
    "    \n",
    "    # Search FAISS index\n",
    "    # We search for more results if filtering by category\n",
    "    search_k = top_k * 10 if category_filter else top_k\n",
    "    distances, indices = index.search(query_embedding, search_k)\n",
    "    \n",
    "    # Prepare results\n",
    "    results = []\n",
    "    for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):\n",
    "        if idx >= 0:  # Valid index\n",
    "            meta = metadata[idx]\n",
    "            \n",
    "            # Apply category filter if specified\n",
    "            if category_filter and meta['category'] != category_filter:\n",
    "                continue\n",
    "            \n",
    "            results.append({\n",
    "                'rank': len(results) + 1,\n",
    "                'score': float(distance),  # Cosine similarity score\n",
    "                'category': meta['category'],\n",
    "                'content': meta['content'],\n",
    "                'source': meta['source'],\n",
    "                'id': meta['id']\n",
    "            })\n",
    "            \n",
    "            if len(results) >= top_k:\n",
    "                break\n",
    "    \n",
    "    print(f\"✓ Found {len(results)} results\\n\")\n",
    "    return results\n",
    "\n",
    "def display_results(results: List[Dict]):\n",
    "    \"\"\"Pretty print search results.\"\"\"\n",
    "    for result in results:\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Rank: {result['rank']} | Score: {result['score']:.4f} | Category: {result['category']}\")\n",
    "        print(f\"Source: {result['source']}\")\n",
    "        print(f\"\\nContent:\\n{result['content'][:300]}...\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test with Sample Queries\n",
    "\n",
    "Let's test the retrieval system with some example queries about sports injuries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 16 queries from requests.txt\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Processing Query 1/16\n",
      "====================================================================================================\n",
      "Query: What rehabilitation methods are most effective for treating knee injuries in badminton players?\n",
      "Searching for top 60 results...\n",
      "✓ Found 60 results\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Processing Query 2/16\n",
      "====================================================================================================\n",
      "Query: What preventive strategies are most effective in reducing the incidence of common injuries among badminton players, and how can these be tailored to different player levels and playing styles?\n",
      "Searching for top 60 results...\n",
      "✓ Found 60 results\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Processing Query 3/16\n",
      "====================================================================================================\n",
      "Query: What are the key factors that influence the recovery time and long-term performance of badminton players after common musculoskeletal injuries?\n",
      "Searching for top 60 results...\n",
      "✓ Found 60 results\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Processing Query 4/16\n",
      "====================================================================================================\n",
      "Query: Summarize the risk factors for low-back pain in professional cyclists and preventive core exercises supported by evidence.\n",
      "Searching for top 60 results...\n",
      "✓ Found 60 results\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Processing Query 5/16\n",
      "====================================================================================================\n",
      "Query: Explain how improper saddle height and reach contribute to knee and hip overuse injuries.\n",
      "Searching for top 60 results...\n",
      "✓ Found 60 results\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Processing Query 6/16\n",
      "====================================================================================================\n",
      "Query: Describe a first-aid protocol for road rash and abrasions after a cycling crash.\n",
      "Searching for top 60 results...\n",
      "✓ Found 60 results\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Processing Query 7/16\n",
      "====================================================================================================\n",
      "Query: What is runner’s knee?\n",
      "Searching for top 60 results...\n",
      "✓ Found 60 results\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Processing Query 8/16\n",
      "====================================================================================================\n",
      "Query: How do different types of running shoes (minimalist vs. cushioned) affect tibial stress and injury risk?\n",
      "Searching for top 60 results...\n",
      "✓ Found 60 results\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Processing Query 9/16\n",
      "====================================================================================================\n",
      "Query: How should one design a progressive rehabilitation training plan for Iliotibial Band Syndrome (ITBS)\n",
      "Searching for top 60 results...\n",
      "✓ Found 60 results\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Processing Query 10/16\n",
      "====================================================================================================\n",
      "Query: An amateur footballer experienced sudden sharp pain in the back of the thigh while sprinting and could not continue running. Based on on-field signs and typical mechanisms, how to recognize a hamstring strain and decide if it’s mild or severe?\n",
      "Searching for top 60 results...\n",
      "✓ Found 60 results\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Processing Query 11/16\n",
      "====================================================================================================\n",
      "Query: I want to reduce injury risk through warm-up routines. What are the most effective warm-up exercises or programs I can implement each week?\n",
      "Searching for top 60 results...\n",
      "✓ Found 60 results\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Processing Query 12/16\n",
      "====================================================================================================\n",
      "Query: Our team increased training intensity recently. How can I monitor whether players are at higher risk of injury?\n",
      "Searching for top 60 results...\n",
      "✓ Found 60 results\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Processing Query 13/16\n",
      "====================================================================================================\n",
      "Query: What causes shoulder pain in swimmers, and how can bad stroke technique or muscle fatigue make it worse?\n",
      "Searching for top 60 results...\n",
      "✓ Found 60 results\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Processing Query 14/16\n",
      "====================================================================================================\n",
      "Query: Why do breaststroke and freestyle put stress on different body parts, and what drills help protect the knees and lower back?\n",
      "Searching for top 60 results...\n",
      "✓ Found 60 results\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Processing Query 15/16\n",
      "====================================================================================================\n",
      "Query: What are the best rehab or strengthening exercises for swimmers coming back from shoulder or back injuries?\n",
      "Searching for top 60 results...\n",
      "✓ Found 60 results\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Processing Query 16/16\n",
      "====================================================================================================\n",
      "Query: Why do female swimmers get injured more often, and what can they do in training or nutrition to lower that risk?\n",
      "Searching for top 60 results...\n",
      "✓ Found 60 results\n",
      "\n",
      "\n",
      "✓ All 16 queries processed!\n",
      "✓ Results saved to: retrievals.txt\n"
     ]
    }
   ],
   "source": [
    "# Read test requests from requests.txt\n",
    "with open('requests.txt', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Split by empty lines and filter out empty strings\n",
    "queries = [q.strip() for q in content.split('\\n\\n') if q.strip()]\n",
    "\n",
    "print(f\"✓ Loaded {len(queries)} queries from requests.txt\\n\")\n",
    "\n",
    "# Process each query and store results\n",
    "output_file = 'faiss_retrievals.txt'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"# FAISS Retrieval Results\\n\")\n",
    "    f.write(\"=\" * 100 + \"\\n\\n\")\n",
    "    \n",
    "    for i, query in enumerate(queries, 1):\n",
    "        print(f\"\\n{'='*100}\")\n",
    "        print(f\"Processing Query {i}/{len(queries)}\")\n",
    "        print(f\"{'='*100}\")\n",
    "        \n",
    "        # Search for similar chunks (top 60 results)\n",
    "        results = search_similar_chunks(query, index, metadata, top_k=60)\n",
    "        \n",
    "        # Write to file\n",
    "        f.write(f\"## QUERY {i}\\n\")\n",
    "        f.write(f\"{query}\\n\\n\")\n",
    "        f.write(f\"Results: {len(results)} chunks retrieved\\n\")\n",
    "        f.write(\"-\" * 100 + \"\\n\\n\")\n",
    "        \n",
    "        # Write each result\n",
    "        for result in results:\n",
    "            f.write(f\"Rank: {result['rank']} | Score: {result['score']:.4f} | Category: {result['category']} | ID: {result['id']}\\n\")\n",
    "            f.write(f\"Source: {result['source']}\\n\")\n",
    "            f.write(f\"Content: {result['content']}\\n\")\n",
    "            f.write(\"-\" * 100 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"=\" * 100 + \"\\n\\n\")\n",
    "\n",
    "print(f\"\\n✓ All {len(queries)} queries processed!\")\n",
    "print(f\"✓ Results saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing retrievals.txt...\n",
      "\n",
      "====================================================================================================\n",
      "RETRIEVAL SUMMARY - Truth IDs\n",
      "====================================================================================================\n",
      "\n",
      "Query 1: What rehabilitation methods are most effective for treating knee injuries in badminton players?\n",
      "IDs: 356,371,385,380,376,457,252,377,358,384,375,183,453,440,50,372,290,444,381,362,284,398,360,359,501,512,177,296,387,450,24,208,223,222,379,357,43,172,40,470,166,205,47,369,286,366,238,405,204,333,365,283,331,197,225,181,206,230,282,231\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query 2: What preventive strategies are most effective in reducing the incidence of common injuries among badminton players, and how can these be tailored to different player levels and playing styles?\n",
      "IDs: 361,405,387,330,409,50,344,208,512,348,332,43,225,358,474,328,26,385,356,333,360,345,243,375,222,380,252,371,205,166,223,241,376,53,410,24,372,329,388,44,207,296,511,384,245,359,206,290,477,429,236,478,522,284,45,381,27,526,436,476\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query 3: What are the key factors that influence the recovery time and long-term performance of badminton players after common musculoskeletal injuries?\n",
      "IDs: 377,385,380,356,371,358,208,223,360,331,375,405,409,384,376,381,53,379,470,387,346,24,252,398,40,43,512,44,237,372,453,334,397,245,182,207,457,236,436,362,26,388,238,177,283,224,440,333,361,444,225,474,490,232,222,284,45,429,205,407\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query 4: Summarize the risk factors for low-back pain in professional cyclists and preventive core exercises supported by evidence.\n",
      "IDs: 934,5060,932,935,962,878,1313,1384,1402,879,4339,946,1624,4971,1403,1156,1126,1386,866,937,1125,944,964,1390,1130,880,1124,1740,947,1154,1261,1625,894,4328,897,1727,933,1298,1284,1155,3879,965,945,895,1254,1296,1391,1389,1127,1122,863,861,5212,1746,963,3604,1396,1387,2902,1314\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query 5: Explain how improper saddle height and reach contribute to knee and hip overuse injuries.\n",
      "IDs: 1689,947,1298,1313,962,1386,1126,961,1262,874,1314,963,1734,946,1399,1151,934,1696,869,1240,1394,1396,1254,1146,866,1284,933,1121,1698,897,852,2502,1674,2461,1263,1148,1727,1384,1740,454,1683,1127,1694,872,1155,895,1129,1264,49,1388,1149,788,861,2505,4336,1265,878,2476,965,877\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query 6: Describe a first-aid protocol for road rash and abrasions after a cycling crash.\n",
      "IDs: 521,1624,880,1727,1746,542,362,934,592,3731,537,787,878,933,1284,1600,1254,428,1253,551,173,3202,2502,3433,1261,3140,784,2505,3733,2419,879,866,540,944,1625,2168,4961,785,1272,1265,174,383,897,1698,1735,1599,881,895,863,2320,1390,553,1130,363,3209,3141,3213,3382,875,175\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query 7: What is runner’s knee?\n",
      "IDs: 2461,2457,2460,2462,2459,2466,2614,2458,2463,2567,2093,2562,2473,2467,2476,2468,520,2464,2621,2501,2159,2470,2474,2152,1388,2095,2469,2465,534,2181,2154,1262,1734,1121,888,1127,946,2534,2613,1386,1126,2166,2472,2414,895,1314,965,1970,2413,963,4335,4337,2120,2528,1736,2048,4336,874,2091,2623\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query 8: How do different types of running shoes (minimalist vs. cushioned) affect tibial stress and injury risk?\n",
      "IDs: 1972,2010,1971,2013,1973,2008,1969,2497,2009,2368,2011,2366,2369,2371,2498,1970,2006,2012,2373,1991,2465,1987,2126,2127,2370,2314,3047,1741,2005,2529,1992,2530,2094,2413,1975,2367,1254,2476,2528,2614,2125,2414,2623,2108,2004,2124,2562,2563,49,2415,2093,2615,2531,2613,51,2372,3109,2461,2509,2361\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query 9: How should one design a progressive rehabilitation training plan for Iliotibial Band Syndrome (ITBS)\n",
      "IDs: 2549,892,893,1739,2503,1738,1267,2557,2358,2553,174,3207,1740,2253,2417,2556,267,1254,2260,1265,2550,2331,268,396,3206,2320,3666,2322,1735,963,2093,395,2045,4763,400,399,3202,3604,254,383,1314,256,2042,3493,838,956,4656,377,2335,2473,173,1736,3209,2363,393,362,1264,251,2127,2254\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query 10: An amateur footballer experienced sudden sharp pain in the back of the thigh while sprinting and could not continue running. Based on on-field signs and typical mechanisms, how to recognize a hamstring strain and decide if it’s mild or severe?\n",
      "IDs: 3196,3484,3192,3199,3193,3043,3212,3211,3191,3195,4374,3197,2167,4354,4380,4379,3200,4375,2895,3202,2166,4376,4383,4355,3207,4353,3046,2901,3042,2093,3201,3213,3206,3047,3208,3489,4351,4358,4014,3486,2159,4105,207,3188,4015,174,2168,2550,3203,3209,3290,237,4359,4382,2169,2891,3567,1736,2614,4349\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query 11: I want to reduce injury risk through warm-up routines. What are the most effective warm-up exercises or programs I can implement each week?\n",
      "IDs: 4100,3599,523,4116,383,3605,2903,4028,4115,3596,3382,4039,3604,4118,2834,2823,51,2905,3603,3291,2822,4042,2906,431,3314,459,2828,4027,2108,2840,2838,2908,4044,3317,2904,2045,3595,5517,4064,3483,2568,4016,2833,2824,4043,399,395,3493,480,4098,4415,396,3292,2826,3302,2127,2254,460,2259,2320\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query 12: Our team increased training intensity recently. How can I monitor whether players are at higher risk of injury?\n",
      "IDs: 431,430,3785,432,3808,3796,2803,3798,3066,3782,4474,4373,3761,3383,3762,3511,3387,4382,3806,3810,3529,3760,3779,2735,4364,3390,3802,325,3510,4404,3809,3786,4379,3526,2751,3386,3528,383,4956,2838,3530,3051,2736,3055,4369,3804,4039,3604,4407,2900,3788,4418,3388,3384,3597,3791,3790,3532,3598,2753\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query 13: What causes shoulder pain in swimmers, and how can bad stroke technique or muscle fatigue make it worse?\n",
      "IDs: 5519,5484,5515,5499,4348,5516,4810,5483,5181,5406,5402,4416,5500,4970,4346,4994,4329,4390,4832,5176,5485,5182,4801,4834,5073,4646,5449,4800,4341,4332,4644,4389,4334,5054,5072,5399,5514,4850,5496,5071,5397,5490,5447,4486,5055,5512,4386,5059,5521,5106,4837,5074,4799,5087,5393,5053,5103,4388,4414,5460\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query 14: Why do breaststroke and freestyle put stress on different body parts, and what drills help protect the knees and lower back?\n",
      "IDs: 5518,4389,5061,4417,4336,4970,5393,5405,4337,5059,4346,4653,4334,5495,4348,4649,5060,4800,4971,5397,5406,4972,4335,4327,5486,4339,4329,5053,4414,4648,4386,5058,5492,5402,5291,5494,4813,5398,4801,4799,6022,4342,4994,4940,4721,5516,4650,4810,5491,6016,4646,4328,5512,4644,4415,5395,6020,4975,4811,4709\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query 15: What are the best rehab or strengthening exercises for swimmers coming back from shoulder or back injuries?\n",
      "IDs: 5521,4646,5402,4486,5522,5400,4763,4648,5181,4346,4342,5515,5053,4644,4416,5484,5500,5519,5516,4348,5397,4994,4841,5398,4389,5393,4654,4837,4800,5290,5496,5483,4327,5514,4386,5073,4656,4838,6020,5406,4388,5449,5060,4764,5520,4334,4390,4329,4655,4341,5293,5182,4832,5399,4417,5499,5517,4991,5054,4409\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query 16: Why do female swimmers get injured more often, and what can they do in training or nutrition to lower that risk?\n",
      "IDs: 4414,4413,4386,4998,5293,4327,5289,5546,4420,5503,5288,4993,5270,5271,5402,5393,4390,5290,4984,5397,4415,5395,5272,4417,5512,5514,5544,5053,4388,4994,5280,4348,5269,5282,4997,5406,5449,4940,4969,5283,5479,5405,4991,5277,5276,4335,4985,5515,4986,4970,4419,4389,4975,4968,5478,5448,4971,5518,4336,4418\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "✓ Summary saved to: retrieval_summary.txt\n",
      "✓ Total queries processed: 16\n"
     ]
    }
   ],
   "source": [
    "# Summarize retrievals.txt - Extract only IDs for each query\n",
    "import re\n",
    "\n",
    "print(\"Summarizing retrievals.txt...\")\n",
    "\n",
    "with open('faiss_retrievals.txt', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Split by query sections\n",
    "query_sections = content.split('## QUERY ')\n",
    "\n",
    "# Skip the header (first split element)\n",
    "query_sections = query_sections[1:]\n",
    "\n",
    "# Parse each query section\n",
    "summary = []\n",
    "for section in query_sections:\n",
    "    lines = section.split('\\n')\n",
    "    \n",
    "    # First line is the query number\n",
    "    query_num = lines[0].strip()\n",
    "    \n",
    "    # Second line is the query text\n",
    "    query_text = lines[1].strip() if len(lines) > 1 else ''\n",
    "    \n",
    "    # Extract all IDs from this section\n",
    "    ids = []\n",
    "    for line in lines:\n",
    "        # Look for lines like \"Rank: 1 | Score: 0.7742 | Category: badminton | ID: 356\"\n",
    "        match = re.search(r'\\| ID: (\\d+)', line)\n",
    "        if match:\n",
    "            ids.append(match.group(1))\n",
    "    \n",
    "    # Store query number and comma-separated IDs\n",
    "    summary.append({\n",
    "        'query_num': query_num,\n",
    "        'query_text': query_text,\n",
    "        'ids': ','.join(ids)\n",
    "    })\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"RETRIEVAL SUMMARY - Truth IDs\")\n",
    "print(f\"{'='*100}\\n\")\n",
    "\n",
    "for item in summary:\n",
    "    print(f\"Query {item['query_num']}: {item['query_text']}\")\n",
    "    print(f\"IDs: {item['ids']}\")\n",
    "    print(f\"{'-'*100}\\n\")\n",
    "\n",
    "# Save summary to file\n",
    "with open('faiss_retrieval_summary.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"# Retrieval Summary - Truth IDs\\n\")\n",
    "    f.write(\"=\" * 100 + \"\\n\\n\")\n",
    "    \n",
    "    for item in summary:\n",
    "        f.write(f\"Query {item['query_num']}: {item['query_text']}\\n\")\n",
    "        f.write(f\"IDs: {item['ids']}\\n\\n\")\n",
    "\n",
    "print(f\"✓ Summary saved to: retrieval_summary.txt\")\n",
    "print(f\"✓ Total queries processed: {len(summary)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save and Load FAISS Index (Optional)\n",
    "\n",
    "Save the index to disk for reuse without re-parsing the SQL dump.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save FAISS index\n",
    "index_file = '/Users/apple/Desktop/sports_injuries.faiss'\n",
    "metadata_file = '/Users/apple/Desktop/sports_injuries_metadata.json'\n",
    "\n",
    "print(\"Saving FAISS index and metadata...\")\n",
    "faiss.write_index(index, index_file)\n",
    "\n",
    "with open(metadata_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✓ Index saved to: {index_file}\")\n",
    "print(f\"✓ Metadata saved to: {metadata_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FAISS index (for future use)\n",
    "def load_faiss_index(index_file: str, metadata_file: str):\n",
    "    \"\"\"Load saved FAISS index and metadata.\"\"\"\n",
    "    print(\"Loading FAISS index...\")\n",
    "    index = faiss.read_index(index_file)\n",
    "    \n",
    "    with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    print(f\"✓ Loaded index with {index.ntotal} vectors\")\n",
    "    print(f\"✓ Loaded {len(metadata)} metadata records\")\n",
    "    \n",
    "    return index, metadata\n",
    "\n",
    "# Example usage:\n",
    "# index, metadata = load_faiss_index(index_file, metadata_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've successfully built a FAISS vector retrieval system! Here's what we did:\n",
    "\n",
    "1. ✓ **Parsed SQL dump** - Extracted 6000+ chunks with embeddings directly from the file\n",
    "2. ✓ **Built FAISS index** - Created IndexFlatIP with normalized vectors for cosine similarity\n",
    "3. ✓ **Set up OpenAI API** - Configured query embedding generation with text-embedding-3-small\n",
    "4. ✓ **Implemented search** - Created functions to search and retrieve relevant chunks\n",
    "5. ✓ **Tested retrieval** - Verified with sample queries\n",
    "6. ✓ **Saved index** - Persisted FAISS index and metadata for reuse\n",
    "\n",
    "### Key Points to Remember:\n",
    "- ⚠️ Always **normalize vectors** with `faiss.normalize_L2()` for cosine similarity\n",
    "- ⚠️ Use the **same embedding model** (text-embedding-3-small) for queries\n",
    "- ⚠️ `IndexFlatIP` is perfect for 6000 records - no need for complex indexes\n",
    "- ✓ FAISS provides **fast vector search** without needing a database\n",
    "- ✓ You can optionally **filter by category** in post-processing\n",
    "\n",
    "### Next Steps:\n",
    "- Set your `OPENAI_API_KEY` environment variable\n",
    "- Run the notebook cells in order\n",
    "- Test with your own queries\n",
    "- Compare results with PostgreSQL/Elasticsearch if needed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
